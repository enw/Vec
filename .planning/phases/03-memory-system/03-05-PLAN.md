---
phase: 03-memory-system
plan: 05
type: execute
wave: 3
depends_on: ["03-03", "03-04"]
files_modified:
  - src/cli/app.tsx
  - src/workspace/ConversationStore.ts
  - src/memory/index.ts
autonomous: false

must_haves:
  truths:
    - "Conversation uses token-aware loading instead of loading all messages"
    - "Summarization triggers automatically after each conversation turn"
    - "HEARTBEAT.md updates during active conversation"
    - "App recovers gracefully from crashes with all state intact"
    - "All 8 MEM requirements satisfied end-to-end"
  artifacts:
    - path: "src/cli/app.tsx"
      provides: "Full integration of token-aware loading, summarization, heartbeat"
      contains: "TokenAwareLoader"
  key_links:
    - from: "src/cli/app.tsx"
      to: "src/memory/TokenAwareLoader.ts"
      via: "loadWithinBudget for message history"
      pattern: "loadWithinBudget"
    - from: "src/cli/app.tsx"
      to: "src/memory/MessageSummarizer.ts"
      via: "checkAndSummarize after each turn"
      pattern: "checkAndSummarize"
    - from: "src/cli/app.tsx"
      to: "src/memory/HeartbeatManager.ts"
      via: "startTask/completeTask around streaming"
      pattern: "startTask|completeTask"
---

<objective>
Wire all memory subsystems into the app: token-aware message loading, automatic summarization check after each turn, heartbeat updates during conversation. Then verify the complete memory system end-to-end.

Purpose: Plans 01-04 created the parts. This plan connects them into a working whole and verifies all 8 MEM requirements.
Output: Fully integrated memory system, visual verification checkpoint.
</objective>

<execution_context>
@/Users/enw/.claude/get-shit-done/workflows/execute-plan.md
@/Users/enw/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-memory-system/03-CONTEXT.md
@.planning/phases/03-memory-system/03-01-SUMMARY.md
@.planning/phases/03-memory-system/03-02-SUMMARY.md
@.planning/phases/03-memory-system/03-03-SUMMARY.md
@.planning/phases/03-memory-system/03-04-SUMMARY.md
@src/cli/app.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire token-aware loading and summarization into App</name>
  <files>
    src/cli/app.tsx
    src/workspace/ConversationStore.ts
  </files>
  <action>
    1. Update `src/workspace/ConversationStore.ts`:
       - Add `async rewrite(messages: Message[]): Promise<void>` method
         - Writes all messages as JSONL (using write-file-atomic for safety)
         - Used by summarizer to replace conversation file
       - Add line-by-line error recovery to `loadAll()`:
         - Wrap each JSON.parse in try/catch
         - Skip corrupted lines with console.warn
         - Continue processing remaining lines (don't fail entire load)

    2. Update `src/cli/app.tsx` to integrate all memory subsystems:

       **On mount (after profile loading from Plan 03):**
       - Create TokenCounter with the Anthropic client instance
       - Create TokenAwareLoader with counter + store
       - Create MessageSummarizer with tokenAwareLoader + workspacePath + client config
       - Create HeartbeatManager with profileManager + workspaceName
       - Replace `store.loadAll()` in useConversation with tokenAwareLoader.loadWithinBudget({ systemPrompt })
         - This means useConversation needs to accept a loader function instead of just store, OR
         - Load messages via TokenAwareLoader before passing to useConversation as initial messages
         - Simpler approach: load via TokenAwareLoader on mount, pass result to useConversation

       **On each handleSubmit:**
       - Before streaming: call heartbeat.startTask('Processing message...')
       - After streaming completes (in onComplete callback):
         - Call heartbeat.completeTask()
         - Call summarizer.checkAndSummarize() (fire-and-forget, non-blocking)

       **On handleSubmit - message building:**
       - Use tokenAwareLoader.loadWithinBudget({ systemPrompt }) to get token-bounded history
       - Build LLM messages from bounded history (not from all messages in state)
       - This ensures we never exceed context window

    3. Update useConversation hook to support initial messages from TokenAwareLoader:
       - Add optional `initialMessages` parameter
       - If provided, skip loadAll on mount and use initialMessages
       - OR: keep loadAll for display (show all messages in UI) but use TokenAwareLoader for LLM calls only
       - PREFER: Show all messages in UI (user can scroll), but send only token-bounded messages to LLM

    Important distinction: UI shows ALL messages (including old ones). LLM receives only token-bounded messages. This means:
    - useConversation.messages = all messages (for display)
    - handleSubmit uses tokenAwareLoader.loadWithinBudget() for LLM input
  </action>
  <verify>
    - `npx tsc --noEmit` passes
    - `pnpm build` succeeds
    - Start vec, send a message -> heartbeat shows active during streaming, completed after
    - Conversation JSONL line corruption doesn't crash app (skips bad lines)
  </verify>
  <done>App uses token-bounded history for LLM calls, triggers summarization check after each turn, updates heartbeat during conversation</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete memory system: profiles created on first launch, SOUL.md as system prompt, token-aware loading, background summarization trigger, heartbeat tracking, crash recovery</what-built>
  <how-to-verify>
    1. Delete any existing workspace data: `rm -rf ~/.local/share/vec/`
    2. Run `pnpm build && node dist/cli/index.js`
    3. Verify: 5 profile files created:
       - `~/.local/share/vec/profiles/USER.md` (global)
       - `~/.local/share/vec/profiles/IDENTITY.md` (global)
       - `~/.local/share/vec/workspaces/{name}/SOUL.md` (workspace)
       - `~/.local/share/vec/workspaces/{name}/AGENTS.md` (workspace)
       - `~/.local/share/vec/workspaces/{name}/HEARTBEAT.md` (workspace)
    4. Send a message -> assistant should respond with personality matching SOUL.md defaults (helpful, concise, direct)
    5. Check HEARTBEAT.md during/after response -> should show status changes
    6. Edit SOUL.md personality to something distinctive (e.g., "Speaks like a pirate")
    7. Restart vec, send message -> assistant personality should reflect edited SOUL.md
    8. Verify conversation persists across restart (previous messages visible)
    9. Corrupt a profile's YAML (add invalid syntax) -> restart vec -> should repair and warn
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues</resume-signal>
</task>

</tasks>

<verification>
MEM-01: Thread memory bounded by 100k tokens (token-aware loading)
MEM-02: SOUL.md profile created and used as system prompt
MEM-03: AGENTS.md profile created (used in future phases)
MEM-04: USER.md profile created and included in system prompt
MEM-05: IDENTITY.md profile created (used in future phases)
MEM-06: HEARTBEAT.md tracks current task status
MEM-07: All memory written to disk (atomic writes)
MEM-08: Crash recovery validates and repairs on startup
</verification>

<success_criteria>
- All 8 MEM requirements satisfied
- Token-bounded LLM context (100k limit, hardcoded)
- Proactive summarization check after each turn
- SOUL.md personality shapes responses
- Profiles auto-created on first launch
- Crash recovery works (corrupted profiles repaired)
- HEARTBEAT.md reflects active/idle task status
</success_criteria>

<output>
After completion, create `.planning/phases/03-memory-system/03-05-SUMMARY.md`
</output>
